---
title: "models_with_recipe"
output: html_document
---

```{r packages}
library(gridExtra)
library(ggplot2)
library(corrplot)
library(ResourceSelection)
library(ISLR)
library(pROC)
library(tidyverse)
library(summarytools)
library(glmnet)
library(caret)
library(plotmo)
library(readr)
library(mlbench)
library(gtsummary)
library(rpart)
library(rpart.plot)
library(party)
library(partykit)
library(vip)
library(recipes)


library(skimr)
library(visdat)
library(reshape2)
library(DataExplorer)
library(ggcorrplot)
library(mgcv)
library(klaR)
library(ggridges)
library(AppliedPredictiveModeling)
library(patchwork)
library(Hmisc)
library(groupdata2)
library(reshape)
library(glmnet)
library(MASS)

# General figure set up
knitr::opts_chunk$set(
  # hide warning messages
  warning = FALSE
)
```


## Preprocess

```{r load_data}
theme_set(theme_bw())
hcv <- read.csv("HepatitisCdata.csv")[,-1]
#sum(is.na(hcv)) #31
hcv$Category <- case_when(hcv$Category == '0=Blood Donor' ~ 0,
                          hcv$Category == '0s=suspect Blood Donor' ~ 0,
                          TRUE ~ 1)
hcv$Sex <- factor(hcv$Sex, levels = c("f", "m"))


hcv.numeric <- hcv[,!names(hcv) %in% c("Category", "Sex")]
hcv.factor <- hcv[,!names(hcv) %in% colnames(hcv.numeric)]
hcv.factor <- hcv.factor[,!names(hcv.factor) %in% "Category"]

y <- hcv$Category
hcv$Category <- as.factor(ifelse(hcv$Category == 1, "patient", "donor"))
hcv$Sex <- factor(as.numeric(hcv$Sex)-1)
```

```{r train_test_split}
set.seed(2022)
rowTrain <- createDataPartition(y = hcv$Category, p = 0.7, list = FALSE)
options(na.action='na.pass')

hcv.train.df <- hcv[rowTrain,]
hcv.test.df <- hcv[-rowTrain,]
```


```{r preprocess_with_impute}
preprocess_recipe = recipe(Category ~ ., data = hcv.train.df) %>%
    step_impute_knn(all_predictors(), neighbors = 5) %>%  
    step_BoxCox(all_numeric_predictors()) %>% 
    step_center(all_numeric_predictors()) %>% 
    step_scale(all_numeric_predictors())
```

```{r impute}
set.seed(2022)

prep <- prep(preprocess_recipe, training = hcv.train.df)

# !! apply the preprocessing operations 
hcv.train.df <- bake(prep, new_data = hcv.train.df)
hcv.test.df <- bake(prep, new_data = hcv.test.df)

hcv.train.x <- model.matrix(~.-1,hcv[rowTrain,])
hcv.train.y <- hcv$Category[rowTrain]
hcv.test.x <- model.matrix(~.-1,hcv[-rowTrain,])
hcv.test.y <- hcv$Category[-rowTrain]
```

## Training models

```{r glm, cache=TRUE}
ctrl <- trainControl(method = "repeatedcv",
                    repeats = 5,
                    #summaryFunction = twoClassSummary,
                    classProbs = TRUE)
# Convert Sex to dummy variable
trainData.dummy <- model.matrix(Category~., hcv.train.df)[,-1]

set.seed(2022)
# glm
model.glm <- train(Category~.,
                   data = hcv.train.df,
                   method = "glm",
                   metric = "Accuracy",
                   trControl = ctrl,
                   na.action = na.pass)
# penalized glm

library(parallel) 
library(doParallel)
# Calculate the number of cores
no_cores <- detectCores() - 1

# create the cluster for caret to use
# CPU usage may go up to 100%
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)

glmnGrid <- expand.grid(alpha = seq(0, 1, length = 21), lambda = exp(seq(2,-6, length = 50)))
model.glmn <- train(Category~.,
                   data = hcv.train.df,
                   method = "glmnet",
                   tuneGrid = glmnGrid,
                   metric = "Accuracy",
                   trControl = ctrl,
                   na.action = na.pass)

stopCluster(cl)
registerDoSEQ()


model.glmn$bestTune
myCol <- rainbow(50)
myPar <- list(
    superpose.symbol = list(col = myCol),
    superpose.line = list(col = myCol)
)
tuning <- ggplot(model.glmn,par.settings = myPar, highlight = TRUE) + scale_x_log10() + ggtitle("GLM tuning parameters")

tuning
```

```{r gam, cache=TRUE}
set.seed(2022)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.gam <- train(Category~.,
                   data = hcv.train.df,
                   method = "gam",
                   metric = "Accuracy",
                   trControl = ctrl,
                   na.action = na.pass)
stopCluster(cl)
registerDoSEQ()
model.gam$finalModel
model.gam$bestTune
```

```{r mars, cache=TRUE}
set.seed(2022)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.mars <- train(Category~.,
                    data = hcv.train.df,
                    method = "earth",
                    tuneGrid = expand.grid(degree = 1:4, nprune = 2:23),
                    metric = "Accuracy",
                    trControl = ctrl,
                    na.action = na.pass)
stopCluster(cl)
registerDoSEQ()

ggplot(model.mars, highlight  = TRUE)
model.mars$finalModel
model.mars$bestTune
```

```{r lda}
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.lda <- train(Category~.,
                   data = hcv.train.df,
                   method = "lda",
                   metric = "Accuracy",
                   trControl = ctrl,
                   na.action = na.pass)
stopCluster(cl)
registerDoSEQ()

cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.qda <- train(Category~.,
                   data = hcv.train.df,
                   method = "qda",
                   metric = "Accuracy",
                   trControl = ctrl,
                   na.action = na.pass)
stopCluster(cl)
registerDoSEQ()

cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.nb <- train(Category~.,
                  data = hcv.train.df,
                  method = "nb",
                  tuneGrid = expand.grid(
                      usekernel = c(T, F),
                      fL = 1,
                      adjust = seq(.1, 3, by = .1)
                  ),
                  metric = "Accuracy",
                  trControl = ctrl,
                  na.action = na.pass)
stopCluster(cl)
registerDoSEQ()
plot(model.nb)
model.nb$bestTune
```

```{r tree}
set.seed(2022)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.rpart <- train(Category~.,
                     data = hcv.train.df,
                     method = "rpart",
                     tuneGrid = data.frame(cp = exp(seq(-8, -3, leng = 100))),
                     metric = "Accuracy",
                     trControl = ctrl,
                     na.action = na.pass)
stopCluster(cl)
registerDoSEQ()

ggplot(model.rpart, highlight = TRUE)
plot(as.party(model.rpart$finalModel))
model.rpart$bestTune


cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
set.seed(2022)
model.ctree <- train(Category~.,
                     data = hcv.train.df,
                     method = "ctree",
                     tuneGrid = data.frame(mincriterion = 1 - exp(seq(-2, -1, leng = 100))),
                     metric = "Accuracy",
                     trControl = ctrl,
                     na.action = na.pass)
stopCluster(cl)
registerDoSEQ()

ggplot(model.ctree, highlight = TRUE)
plot(model.ctree$finalModel)
model.ctree$bestTune
```

```{r random_forest, cache=TRUE}
set.seed(2022)

cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
#rf
rf.grid <- expand.grid(mtry = 1:12,
                       splitrule = "gini",
                       min.node.size = seq(from = 1, to = 50, by = 5))
model.rf <- train(Category~.,
                  data = hcv.train.df,
                  method = "ranger",
                  importance = "permutation",
                  tuneGrid = rf.grid,
                  metric = "Accuracy",
                  trControl = ctrl,
                  na.action = na.pass)
stopCluster(cl)
registerDoSEQ()
tuning2 <- ggplot(model.rf, highlight = TRUE)
model.rf$bestTune
```

```{r adaboost}
set.seed(2022)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
adaboost.grid = expand.grid(n.trees = c(4000,5000,6000),
                            interaction.depth = 1:6,
                            shrinkage = c(0.001,0.002,0.004),
                            n.minobsinnode = 1)

model.gbm = train(Category~.,
                  data = hcv.train.df,
                  na.action = na.pass,
                  tuneGrid = adaboost.grid,
                  trControl = ctrl,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "Accuracy",
                  verbose = FALSE)
stopCluster(cl)
registerDoSEQ()
ggplot(model.gbm,highlight = T)

```

```{r svml}
set.seed(2022)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.svml = train(Category~.,
                   data = hcv.train.df,
                   method = "svmLinear",
                   metric = "Accuracy",
                   tuneGrid = data.frame(C = exp(seq(-2,2,len = 200))),
                   trControl = ctrl)
stopCluster(cl)
registerDoSEQ()
plot(model.svml, highlight = TRUE, xTrans = log)
model.svml$bestTune
```

```{r svmr}
svmr.grid = expand.grid(C = exp(seq(-1,4,len = 20)),
                        sigma = exp(seq(-6,-2,len=20)))

set.seed(2022)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
model.svmr = train(Category~.,
                   data = hcv.train.df,
                 method = "svmRadialSigma",
                 tuneGrid = svmr.grid,
                 metric = "Accuracy",
                 trControl = ctrl)

myCol = rainbow(20)
myPar = list(superpose.symbol = list(col = myCol),
             superpose.line = list(col = myCol))
stopCluster(cl)
registerDoSEQ()
plot(model.svmr, hightlight = TRUE, par.settings = myPar)

model.svmr$bestTune
```


```{r nn}

```

```{r save_models}
saveRDS(model.glm, file = "./models/model.glm.rds")
saveRDS(model.glmn, file = "./models/model.glmn.rds")
saveRDS(model.gam, file = "./models/model.gam.rds")
saveRDS(model.mars, file = "./models/model.mars.rds")
saveRDS(model.lda, file = "./models/model.lda.rds")
saveRDS(model.qda, file = "./models/model.qda.rds")
saveRDS(model.nb, file = "./models/model.nb.rds")
saveRDS(model.ctree, file = "./models/model.ctree.rds")
saveRDS(model.rf, file = "./models/model.rf.rds")
saveRDS(model.rpart,file = "./models/model.rpart.rds")
saveRDS(model.gbm, file = "./models/model.gbm.rds")
saveRDS(model.svml, "./models/model.svml.rds")
saveRDS(model.svmr, "./models/model.svmr.rds")
```
